{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_moons(n_samples=500, random_state=42,noise=0.30)\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=42,probability=True)\n",
    "\n",
    "vot_clf = VotingClassifier(estimators=[(\"log\",log_clf), (\"rf\", rf_clf), (\"svm\",  svm_clf)],voting='soft')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rf_clf, svm_clf, vot_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9226666666666666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500, max_samples=100, bootstrap=True, n_jobs= -1,oob_score=True)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.904"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34673367, 0.65326633],\n",
       "       [0.36387435, 0.63612565],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0078125 , 0.9921875 ],\n",
       "       [0.02040816, 0.97959184],\n",
       "       [0.11166253, 0.88833747],\n",
       "       [0.40540541, 0.59459459],\n",
       "       [0.06701031, 0.93298969],\n",
       "       [0.92913386, 0.07086614],\n",
       "       [0.84210526, 0.15789474],\n",
       "       [0.51937984, 0.48062016],\n",
       "       [0.04726368, 0.95273632],\n",
       "       [0.7154047 , 0.2845953 ],\n",
       "       [0.84236453, 0.15763547],\n",
       "       [0.92947103, 0.07052897],\n",
       "       [0.09448819, 0.90551181],\n",
       "       [0.03856041, 0.96143959],\n",
       "       [0.92328767, 0.07671233],\n",
       "       [0.66842105, 0.33157895],\n",
       "       [0.95979899, 0.04020101],\n",
       "       [0.03208556, 0.96791444],\n",
       "       [0.23243243, 0.76756757],\n",
       "       [0.88917526, 0.11082474],\n",
       "       [0.9822335 , 0.0177665 ],\n",
       "       [0.96410256, 0.03589744],\n",
       "       [0.00258398, 0.99741602],\n",
       "       [0.97540984, 0.02459016],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03084833, 0.96915167],\n",
       "       [0.71891892, 0.28108108],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99483204, 0.00516796],\n",
       "       [0.0188172 , 0.9811828 ],\n",
       "       [0.09210526, 0.90789474],\n",
       "       [0.08157895, 0.91842105],\n",
       "       [0.984375  , 0.015625  ],\n",
       "       [0.01322751, 0.98677249],\n",
       "       [0.53517588, 0.46482412],\n",
       "       [0.01574803, 0.98425197],\n",
       "       [0.99737533, 0.00262467],\n",
       "       [0.06527415, 0.93472585],\n",
       "       [0.36813187, 0.63186813],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99232737, 0.00767263],\n",
       "       [0.01269036, 0.98730964],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99740933, 0.00259067],\n",
       "       [0.02842377, 0.97157623],\n",
       "       [0.98391421, 0.01608579],\n",
       "       [0.02088773, 0.97911227],\n",
       "       [0.94629156, 0.05370844],\n",
       "       [0.8469657 , 0.1530343 ],\n",
       "       [0.93667546, 0.06332454],\n",
       "       [0.78514589, 0.21485411],\n",
       "       [0.02227723, 0.97772277],\n",
       "       [0.09162304, 0.90837696],\n",
       "       [0.80407125, 0.19592875],\n",
       "       [0.01038961, 0.98961039],\n",
       "       [0.01799486, 0.98200514],\n",
       "       [0.03038674, 0.96961326],\n",
       "       [0.81975309, 0.18024691],\n",
       "       [0.63588391, 0.36411609],\n",
       "       [0.68229167, 0.31770833],\n",
       "       [0.98910082, 0.01089918],\n",
       "       [0.0078534 , 0.9921466 ],\n",
       "       [0.81298701, 0.18701299],\n",
       "       [0.98453608, 0.01546392],\n",
       "       [0.984375  , 0.015625  ],\n",
       "       [0.61458333, 0.38541667],\n",
       "       [0.97662338, 0.02337662],\n",
       "       [0.32453826, 0.67546174],\n",
       "       [0.32620321, 0.67379679],\n",
       "       [0.40616967, 0.59383033],\n",
       "       [0.66835443, 0.33164557],\n",
       "       [0.00808625, 0.99191375],\n",
       "       [0.31550802, 0.68449198],\n",
       "       [0.8687664 , 0.1312336 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0302267 , 0.9697733 ],\n",
       "       [0.96962025, 0.03037975],\n",
       "       [0.00742574, 0.99257426],\n",
       "       [0.2393617 , 0.7606383 ],\n",
       "       [0.11197917, 0.88802083],\n",
       "       [0.4353562 , 0.5646438 ],\n",
       "       [0.99226804, 0.00773196],\n",
       "       [0.04986877, 0.95013123],\n",
       "       [0.58689459, 0.41310541],\n",
       "       [0.07427056, 0.92572944],\n",
       "       [0.05744125, 0.94255875],\n",
       "       [0.        , 1.        ],\n",
       "       [0.35323383, 0.64676617],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01058201, 0.98941799],\n",
       "       [0.06020942, 0.93979058],\n",
       "       [0.01278772, 0.98721228],\n",
       "       [0.80978261, 0.19021739],\n",
       "       [0.59358289, 0.40641711],\n",
       "       [0.07277628, 0.92722372],\n",
       "       [0.99477807, 0.00522193],\n",
       "       [0.32020997, 0.67979003],\n",
       "       [0.69543147, 0.30456853],\n",
       "       [0.00777202, 0.99222798],\n",
       "       [0.09115282, 0.90884718],\n",
       "       [0.41071429, 0.58928571],\n",
       "       [0.97938144, 0.02061856],\n",
       "       [0.06544503, 0.93455497],\n",
       "       [0.96569921, 0.03430079],\n",
       "       [0.46842105, 0.53157895],\n",
       "       [0.25839793, 0.74160207],\n",
       "       [0.99488491, 0.00511509],\n",
       "       [0.19160105, 0.80839895],\n",
       "       [0.85793872, 0.14206128],\n",
       "       [0.26666667, 0.73333333],\n",
       "       [0.77368421, 0.22631579],\n",
       "       [0.98955614, 0.01044386],\n",
       "       [0.99234694, 0.00765306],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00255102, 0.99744898],\n",
       "       [0.47512438, 0.52487562],\n",
       "       [0.99193548, 0.00806452],\n",
       "       [0.08205128, 0.91794872],\n",
       "       [0.99234694, 0.00765306],\n",
       "       [0.95928753, 0.04071247],\n",
       "       [0.99736148, 0.00263852],\n",
       "       [0.95549738, 0.04450262],\n",
       "       [0.96505376, 0.03494624],\n",
       "       [0.03100775, 0.96899225],\n",
       "       [0.93094629, 0.06905371],\n",
       "       [0.95380435, 0.04619565],\n",
       "       [0.01570681, 0.98429319],\n",
       "       [0.22666667, 0.77333333],\n",
       "       [0.87096774, 0.12903226],\n",
       "       [0.38659794, 0.61340206],\n",
       "       [0.90837696, 0.09162304],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03608247, 0.96391753],\n",
       "       [0.75757576, 0.24242424],\n",
       "       [0.7191601 , 0.2808399 ],\n",
       "       [0.50777202, 0.49222798],\n",
       "       [0.83806818, 0.16193182],\n",
       "       [0.90523691, 0.09476309],\n",
       "       [0.13715711, 0.86284289],\n",
       "       [0.79891304, 0.20108696],\n",
       "       [0.03778338, 0.96221662],\n",
       "       [0.0078125 , 0.9921875 ],\n",
       "       [0.07777778, 0.92222222],\n",
       "       [0.73097826, 0.26902174],\n",
       "       [0.95355191, 0.04644809],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03713528, 0.96286472],\n",
       "       [0.00533333, 0.99466667],\n",
       "       [0.09487179, 0.90512821],\n",
       "       [0.03664921, 0.96335079],\n",
       "       [0.99494949, 0.00505051],\n",
       "       [0.98684211, 0.01315789],\n",
       "       [0.86528497, 0.13471503],\n",
       "       [0.9973545 , 0.0026455 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.89690722, 0.10309278],\n",
       "       [0.01020408, 0.98979592],\n",
       "       [0.67692308, 0.32307692],\n",
       "       [0.32249322, 0.67750678],\n",
       "       [0.0525    , 0.9475    ],\n",
       "       [0.00508906, 0.99491094],\n",
       "       [0.37903226, 0.62096774],\n",
       "       [0.99465241, 0.00534759],\n",
       "       [0.96335079, 0.03664921],\n",
       "       [0.00253807, 0.99746193],\n",
       "       [0.99197861, 0.00802139],\n",
       "       [0.064     , 0.936     ],\n",
       "       [0.00527704, 0.99472296],\n",
       "       [0.94960212, 0.05039788],\n",
       "       [0.01028278, 0.98971722],\n",
       "       [0.00514139, 0.99485861],\n",
       "       [0.99742268, 0.00257732],\n",
       "       [0.01518987, 0.98481013],\n",
       "       [0.82597403, 0.17402597],\n",
       "       [0.90512821, 0.09487179],\n",
       "       [0.05655527, 0.94344473],\n",
       "       [0.96398892, 0.03601108],\n",
       "       [0.93224932, 0.06775068],\n",
       "       [0.97964377, 0.02035623],\n",
       "       [0.01282051, 0.98717949],\n",
       "       [0.0129199 , 0.9870801 ],\n",
       "       [0.99457995, 0.00542005],\n",
       "       [0.22976501, 0.77023499],\n",
       "       [0.99234694, 0.00765306],\n",
       "       [0.08616188, 0.91383812],\n",
       "       [0.03108808, 0.96891192],\n",
       "       [0.98941799, 0.01058201],\n",
       "       [0.        , 1.        ],\n",
       "       [0.14285714, 0.85714286],\n",
       "       [0.88541667, 0.11458333],\n",
       "       [0.90885417, 0.09114583],\n",
       "       [0.61662198, 0.38337802],\n",
       "       [0.69010417, 0.30989583],\n",
       "       [0.02295918, 0.97704082],\n",
       "       [0.24736842, 0.75263158],\n",
       "       [0.98958333, 0.01041667],\n",
       "       [0.92612137, 0.07387863],\n",
       "       [0.93947368, 0.06052632],\n",
       "       [0.98214286, 0.01785714],\n",
       "       [0.06332454, 0.93667546],\n",
       "       [0.00787402, 0.99212598],\n",
       "       [0.10540541, 0.89459459],\n",
       "       [0.48691099, 0.51308901],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03108808, 0.96891192],\n",
       "       [0.96143251, 0.03856749],\n",
       "       [0.0848329 , 0.9151671 ],\n",
       "       [0.11904762, 0.88095238],\n",
       "       [0.90237467, 0.09762533],\n",
       "       [0.06084656, 0.93915344],\n",
       "       [0.32975871, 0.67024129],\n",
       "       [0.00787402, 0.99212598],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02645503, 0.97354497],\n",
       "       [0.00793651, 0.99206349],\n",
       "       [0.91560102, 0.08439898],\n",
       "       [0.87848101, 0.12151899],\n",
       "       [0.94892473, 0.05107527],\n",
       "       [0.02094241, 0.97905759],\n",
       "       [0.08607595, 0.91392405],\n",
       "       [0.94594595, 0.05405405],\n",
       "       [0.13350785, 0.86649215],\n",
       "       [0.00531915, 0.99468085],\n",
       "       [0.28311688, 0.71688312],\n",
       "       [0.96930946, 0.03069054],\n",
       "       [0.84450402, 0.15549598],\n",
       "       [0.11749347, 0.88250653],\n",
       "       [0.7486911 , 0.2513089 ],\n",
       "       [0.95918367, 0.04081633],\n",
       "       [0.1377551 , 0.8622449 ],\n",
       "       [0.16      , 0.84      ],\n",
       "       [0.99004975, 0.00995025],\n",
       "       [0.        , 1.        ],\n",
       "       [0.0257732 , 0.9742268 ],\n",
       "       [0.01333333, 0.98666667],\n",
       "       [0.31043956, 0.68956044],\n",
       "       [0.87468031, 0.12531969],\n",
       "       [0.04199475, 0.95800525],\n",
       "       [0.98469388, 0.01530612],\n",
       "       [0.87179487, 0.12820513],\n",
       "       [0.00258398, 0.99741602],\n",
       "       [0.79177378, 0.20822622],\n",
       "       [0.9924812 , 0.0075188 ],\n",
       "       [0.00530504, 0.99469496],\n",
       "       [0.99731903, 0.00268097],\n",
       "       [0.0630137 , 0.9369863 ],\n",
       "       [0.00769231, 0.99230769],\n",
       "       [0.11197917, 0.88802083],\n",
       "       [0.22797927, 0.77202073],\n",
       "       [0.84237726, 0.15762274],\n",
       "       [0.09302326, 0.90697674],\n",
       "       [0.9895288 , 0.0104712 ],\n",
       "       [0.64229765, 0.35770235],\n",
       "       [0.09669211, 0.90330789],\n",
       "       [0.62303665, 0.37696335],\n",
       "       [0.83544304, 0.16455696],\n",
       "       [0.0106383 , 0.9893617 ],\n",
       "       [0.98955614, 0.01044386],\n",
       "       [0.0078534 , 0.9921466 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.7403599 , 0.2596401 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9893617 , 0.0106383 ],\n",
       "       [0.07552083, 0.92447917],\n",
       "       [0.72680412, 0.27319588],\n",
       "       [0.13520408, 0.86479592],\n",
       "       [0.99475066, 0.00524934],\n",
       "       [0.88858696, 0.11141304],\n",
       "       [0.00775194, 0.99224806],\n",
       "       [0.07894737, 0.92105263],\n",
       "       [0.14095745, 0.85904255],\n",
       "       [0.0984456 , 0.9015544 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97668394, 0.02331606],\n",
       "       [0.81060606, 0.18939394],\n",
       "       [0.21138211, 0.78861789],\n",
       "       [0.94293478, 0.05706522],\n",
       "       [0.05454545, 0.94545455],\n",
       "       [0.65374677, 0.34625323],\n",
       "       [0.14578005, 0.85421995],\n",
       "       [0.97142857, 0.02857143],\n",
       "       [0.87792208, 0.12207792],\n",
       "       [0.01340483, 0.98659517],\n",
       "       [0.93732194, 0.06267806],\n",
       "       [0.91420912, 0.08579088],\n",
       "       [0.00516796, 0.99483204],\n",
       "       [0.05759162, 0.94240838],\n",
       "       [0.99460916, 0.00539084],\n",
       "       [0.03296703, 0.96703297],\n",
       "       [0.99747475, 0.00252525],\n",
       "       [0.0839895 , 0.9160105 ],\n",
       "       [0.91176471, 0.08823529],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00543478, 0.99456522],\n",
       "       [0.03896104, 0.96103896],\n",
       "       [0.63358779, 0.36641221],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.65463918, 0.34536082],\n",
       "       [0.8694517 , 0.1305483 ],\n",
       "       [0.9921466 , 0.0078534 ],\n",
       "       [0.66497462, 0.33502538],\n",
       "       [0.45526316, 0.54473684],\n",
       "       [0.04591837, 0.95408163],\n",
       "       [0.82323232, 0.17676768],\n",
       "       [0.01023018, 0.98976982],\n",
       "       [0.99475066, 0.00524934],\n",
       "       [0.77472527, 0.22527473],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99742268, 0.00257732],\n",
       "       [0.83028721, 0.16971279],\n",
       "       [0.26153846, 0.73846154],\n",
       "       [0.16243655, 0.83756345],\n",
       "       [0.2025974 , 0.7974026 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.73138298, 0.26861702],\n",
       "       [0.87373737, 0.12626263],\n",
       "       [0.04986877, 0.95013123],\n",
       "       [0.99738903, 0.00261097],\n",
       "       [0.96111111, 0.03888889],\n",
       "       [0.99736842, 0.00263158],\n",
       "       [0.00815217, 0.99184783],\n",
       "       [0.06976744, 0.93023256],\n",
       "       [0.92913386, 0.07086614],\n",
       "       [0.90957447, 0.09042553],\n",
       "       [0.99744898, 0.00255102],\n",
       "       [0.23316062, 0.76683938],\n",
       "       [0.99210526, 0.00789474],\n",
       "       [0.11586902, 0.88413098],\n",
       "       [0.95300261, 0.04699739],\n",
       "       [0.04935065, 0.95064935],\n",
       "       [0.98153034, 0.01846966],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [0.9919571 , 0.0080429 ],\n",
       "       [0.00258398, 0.99741602],\n",
       "       [0.92051282, 0.07948718],\n",
       "       [0.01871658, 0.98128342],\n",
       "       [0.04010695, 0.95989305],\n",
       "       [0.06842105, 0.93157895],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98655914, 0.01344086],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94385027, 0.05614973],\n",
       "       [0.08469945, 0.91530055],\n",
       "       [0.9921466 , 0.0078534 ],\n",
       "       [0.18829517, 0.81170483],\n",
       "       [0.00753769, 0.99246231],\n",
       "       [0.05291005, 0.94708995],\n",
       "       [0.        , 1.        ],\n",
       "       [0.77718833, 0.22281167],\n",
       "       [0.07219251, 0.92780749],\n",
       "       [0.11627907, 0.88372093],\n",
       "       [0.99745547, 0.00254453],\n",
       "       [0.95165394, 0.04834606],\n",
       "       [0.18766067, 0.81233933],\n",
       "       [0.94915254, 0.05084746],\n",
       "       [0.08208955, 0.91791045],\n",
       "       [0.12073491, 0.87926509],\n",
       "       [0.99193548, 0.00806452],\n",
       "       [0.93386243, 0.06613757],\n",
       "       [0.50385604, 0.49614396],\n",
       "       [0.89701897, 0.10298103],\n",
       "       [0.9974026 , 0.0025974 ],\n",
       "       [0.05291005, 0.94708995],\n",
       "       [0.96765499, 0.03234501],\n",
       "       [0.04878049, 0.95121951],\n",
       "       [0.10909091, 0.89090909],\n",
       "       [0.93947368, 0.06052632],\n",
       "       [1.        , 0.        ],\n",
       "       [0.07506702, 0.92493298],\n",
       "       [0.71025641, 0.28974359]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.10482673067583043\n",
      "sepal width (cm) 0.026375756577450577\n",
      "petal length (cm) 0.4233338439029198\n",
      "petal width (cm) 0.4454636688437992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators = 500, n_jobs=-1)\n",
    "rnd_clf = rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"],rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   learning_rate=0.5, n_estimators=200)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "DecisionTreeClassifier(max_depth = 1), n_estimators=200,algorithm=\"SAMME.R\",learning_rate=0.5)\n",
    "ada_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = y - tree_reg1.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = np.array([[0.8]])\n",
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=2, n_estimators=80)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "gbtr = GradientBoostingRegressor(max_depth = 2,n_estimators=120)\n",
    "gbtr.fit(X_train, y_train)\n",
    "\n",
    "erros = [mean_squared_error(y_val, y_pred) for y_pred in gbtr.staged_predict(X_val)]\n",
    "best_n_estimators = np.argmin(erros) + 1\n",
    "\n",
    "gbtr_best = GradientBoostingRegressor(max_depth = 2, n_estimators = best_n_estimators)\n",
    "gbtr_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtr = GradientBoostingRegressor(max_depth = 2, warm_start=True)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "errors_going_up = 0\n",
    "\n",
    "for n_estimator in range (1,120):\n",
    "    gbtr.n_estimators = n_estimator\n",
    "    gbtr.fit(X_train, y_train)\n",
    "    y_pred = gbtr.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        errors_going_up = 0 \n",
    "    else:\n",
    "        errors_going_up += 1\n",
    "        if errors_going_up == 5:\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b463cf52ca8196c9c2a7ed6997d0666bf4884dc439b687c01213b9631ac3d5d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
